{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA MANIPULATION\n",
    "import numpy as np\n",
    "\n",
    "# DATA VISUALIZATION\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# BLOB DATASET\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# KERAS\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Properly Prevent Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ **Goals of this challenge**\n",
    "- **`Cross Validate`** a Deep Learning Model\n",
    "- Give a **`Validation Set`** to the model\n",
    "- Apply two techniques to prevent overfitting:\n",
    "    - Use the **`Early Stopping`** criterion to prevent the Neural network from over-learning / over-fitting\n",
    "    - **`Regularize`** your network\n",
    "- Analyze the **`impact of the batch size and the number of epochs`** on the training of a Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data - the `blobs` Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Blobs Dataset\n",
    "\n",
    "First, let's generate some data using the [`make_blobs`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) function from Scikit-Learn\n",
    "\n",
    "Generate 2000 samples with 10 features each; there should be 8 classes of blobs (`centers` argument) with `cluster_std` equal to 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset\n",
    "\n",
    "All your samples have 10 features. Plot one of the dimensions against another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding your Categorical Target\n",
    "\n",
    "Use the üìö [**to_categorical()**](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) function to convert `y` to `y_cat`, which is the categorical representation of `y` with **One-Hot encoded** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Cross-Validation in Deep Learning\n",
    "\n",
    "üë©üèª‚Äçüè´ In a previous challenge, we split the dataset into a training set and a testing set at the beginning of the notebook. Then, we started to build different models which were trained on the training set and evaluated on the testing set.\n",
    "\n",
    "So, at the end of the day, we used the testing set every time we evaluated our models and different hyperparameters. This is normal: we always train on the training set and we evaluate on the testing set.\n",
    "\n",
    "However, we selected our \"best model\" based on the score of each model. In other words, we _used_ the test set to select our best model, which means there was ‚ùóÔ∏è `data leakage` ‚ùóÔ∏è\n",
    "\n",
    "ü§î **what should we do?**\n",
    "\n",
    "- A first good practice is to avoid using `random_state` or any deterministic separation between your training and testing sets. In that case, your testing set will change every time you re-run your notebook. This is far from being sufficient, though\n",
    "- To compare models properly, you have to run a cross-validation, a 10-fold split, for instance\n",
    "\n",
    "üßê If you look at [sklearn.model_selection.cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html), this Cross -Validation tool is designed for Machine Learning algorithms implemented in Scikit Learn, whereas we have been creating and using Neural Networks from Tensorflow/Keras.\n",
    "\n",
    "üî• Let's discover how to **Cross-validate a Neural Network**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing a Neural Network\n",
    "\n",
    "First, write a function that generates a Neural Network with 3 layers:\n",
    "\n",
    "<u>Architecture</u>\n",
    "- an **input layer** with 25 neurons, the `relu` activation function and the appropriate `input_dim`\n",
    "- a **hidden layer** with 10 neurons and the `relu` activation function.\n",
    "- a **predictive layer** that is suited to the problem at hand (*multiclass classification*)\n",
    "\n",
    "<u>Compilation</u>\n",
    "\n",
    "The function should include a compilation method with:\n",
    "- the *categorical_crossentropy* loss\n",
    "- the *Adam* optimizer \n",
    "- the *accuracy* metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validating the Neural Net\n",
    "\n",
    "üßëüèª‚Äçüíª Write a _loop_ using the [K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) function from Scikit-Learn.\n",
    "\n",
    "* ‚úÇÔ∏è Choose 10 splits to fit your model on the training data\n",
    "* üß™ Evaluate your model on the testing data, and store the results of the evaluation into a `results` variable.\n",
    "\n",
    "_Hints_:\n",
    "* ‚öñÔ∏è Do not forget to standardize your training data before fitting the NN\n",
    "* üëå 150 epochs should be sufficient for a first approximation\n",
    "* ü§ù As this is your first Deep Learning Cross-Validation, you are guided; just uncomment the following cell and follow the steps\n",
    "* ‚è≥ Notice that we added `%% time` at the beginning of this Jupyter Notebook cell to display its running time, and we encourage you to do so whenever you run expensive computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# kf = KFold(n_splits=10)\n",
    "# kf.get_n_splits(X)\n",
    "\n",
    "# results = []\n",
    "\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     # Split the data into train and test\n",
    "\n",
    "\n",
    "#     # Scaling your data\n",
    "\n",
    "\n",
    "#     # Initialize the model\n",
    "\n",
    "\n",
    "#     # Fit the model on the train data\n",
    "\n",
    "\n",
    "#     # Evaluate the model on the test data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the Cross-Validated Network\n",
    "\n",
    "Print the average accuracy of these 10 folds and the standard deviation of these 10 accuracy values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [_[1] for _ in results]\n",
    "\n",
    "print(f'New mean accuracy: {np.mean(accuracy)*100:.2f}% (¬±{np.std(accuracy)*100:.2f})')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks About the Computational Time\n",
    "\n",
    "- ü§Ø You probably encountered one of the main drawbacks of using proper cross-validation for a Neural Network: **it takes a lot of time**! Therefore, for the rest of the Deep-Learning module, we will do **only one fold**\n",
    "- üëÆüèª‚Äç‚ôÄÔ∏è Remember that this is not entirely correct and, for real-life applications and problems, you are encouraged to use a proper cross-validation technique\n",
    "- üíº In general, people split only once, as you did. Once they get to the end of their optimization, they launch a real cross-validation run at 6 PM, go home and get the final results on the next day"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holdout Method\n",
    "\n",
    "For the rest of the exercise (and of the Deep Learning module), split the dataset into a training set and a testing set with a 70/30% training-to-test data ratio.\n",
    "\n",
    "Make sure to also scale the data after splitting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "SScaler = StandardScaler()\n",
    "SScaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = SScaler.transform(X_train)\n",
    "X_test_scaled = SScaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) How to Prevent a Neural Network from Overfitting?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Early Stopping\n",
    "\n",
    "üö¶ **Stop the learning process before overfitting**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Illustrating How a Neural Network Easily Overfits\n",
    "\n",
    "First things first, let's show that if we train the model for too long (= for too many epochs) it will overfit the training data and will not be good at predicting the testing data.\n",
    "\n",
    "**How can we do it without using the testing data, which is strictly forbidden?**\n",
    "\n",
    "You can use a fraction of the <font color=blue>training set</font> as a <font color=green>validation set</font>.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/lectures/deep-learning/02/validation_set.png\" width=450>\n",
    "\n",
    "With Keras, you don't have to re-use the `train_test_split` method from Scikit-Learn. Instead, you have two options:\n",
    "\n",
    "- `validation_split = 0.2` (for example)\n",
    "    - The model will take the last 20% of the observations in the training set and use this group as the validation holdout set\n",
    "    - If you want a random `train_val_split` within the training set, you can also add the argument `shuffle = True` in `model.fit()`\n",
    "- `validation_data = (X_val, y_val)` if you have access to a dataset that you want to use as the validation holdout set.\n",
    "\n",
    "üëâ Let's go with the first option and set `epochs = 500`. \n",
    "\n",
    "üëâ Store the performances of the model in a `history` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pass  # YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your Neural Network's Performance\n",
    "\n",
    "Evaluate the model on the testing set and print the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learnings About Number of Epochs\n",
    "\n",
    "Plot the history of the model with the `plot_loss_accuracy()` function that we coded for you.\n",
    "\n",
    "What do you observe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "\n",
    "    # --- LOSS --- \n",
    "\n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "\n",
    "    ax[0].set_ylim((0,3))\n",
    "\n",
    "    ax[0].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    # --- ACCURACY\n",
    "\n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "\n",
    "    ax[1].legend(['Train', 'Test'], loc='best')\n",
    "\n",
    "    ax[1].set_ylim((0,1))\n",
    "\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ We clearly see that **the number of epochs we choose has a strong influence on the final results**: \n",
    "\n",
    "**INSUFFICIENT NUMBER OF EPOCHS $\\implies$ UNDERFITTING**:\n",
    "- The algorithm is not optimal as its Loss Function has **not converged yet**\n",
    "- It hasn't learned enough from the training data\n",
    "\n",
    "**TOO MANY EPOCHS** $\\implies$ **OVERFITTING**: \n",
    "- Our Neural Network has **learned too much** from the training data, including its noisy information\n",
    "- the algorithm **does not generalize well** on test data\n",
    "\n",
    "üö¶ Basically, what we want to do is stop the algorithm **when the test loss is minimal** (or when the testing metrics are maximal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early Stopping\n",
    "\n",
    "üßëüèª‚Äçüè´ Let's introduce the **Early Stopping** criterion.\n",
    "\n",
    "The Early Stopping criterion is a way to **automatically stop the training of the algorithm** before reaching the number of epochs that was originally set.\n",
    "\n",
    "üïµüèª‚Äç‚ôÇÔ∏è **How does it work?**\n",
    "\n",
    "The model will pay attention to the **<font color=green>loss of the validation set</font>**. If <font color=green>it</font> starts increasing again üìà while the <font color=blue>loss of the training set</font> keeps decreasing üìâ, it is a good sign that the model is overfitting and the training should be stopped!\n",
    "\n",
    "\n",
    "<img src=\"validation_set.png\" alt=\"Validation set\" width=450/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observing the Early Stopping Criterion\n",
    "\n",
    "Run the following code and plot the history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "es = EarlyStopping()\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "# Fit the model on the train data\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split = 0.3,\n",
    "    epochs = 500,\n",
    "    batch_size = 16, \n",
    "    verbose = 1, \n",
    "    callbacks = [es] # This will call the Early Stopping Criterion for each epoch\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluate the ES Model\n",
    "\n",
    "_(also look at the historical losses)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùó **The problem with strict Early Stopping** ‚ùó \n",
    "\n",
    "The problem with this type of approach is that as soon as the loss of the validation set increases, the model stops. However, as a Neural Network's convergence is stochastic, the loss may slightly increase before decreasing again.\n",
    "\n",
    "‚úÖ The `EarlyStopping` criterion has a `patience` keyword that defines how many **consecutive epochs without any loss decrease** are allowed in the validation set before we stop the training procedure.\n",
    "\n",
    "Use the `EarlyStopping` criterion with a patience term of 30 epochs, plot the results, and print the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüè´ **Remarks**\n",
    "\n",
    "\n",
    "- üìâ The model continues to converge even though its Loss Function had some consecutive loss increases/decreases w.r.t. to the number of epochs\n",
    "- ü§∑üèª‚Äç‚ôÇÔ∏è The `patience` number to select is highly related to the task at hand, and there is no general rule of thumb\n",
    "- üßëüèª‚Äçüè´ If you selected a high patience value for your Early Stopping:\n",
    "    - ü§û your Neural Network should theoretically still stop training before the end (not always the case if your number of epochs is too low)\n",
    "    - ‚ùóÔ∏è your validation loss will increase again after reaching a minimum value, but ideally, you want it to be as low as possible; the validation loss potentially reaches a minimum for certain weights at a certain epoch\n",
    "        - ü§î How to find these weights?\n",
    "\n",
    "üìö The `EarlyStopping` criterion enables you to:\n",
    "- stop the convergence\n",
    "- restore the best weights of the NN when it had the lowest error level (or the best score) on the validation set, thanks to `restore_best_weights = True` (set to `False` by default)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Restoring the Best Weights of a Model\n",
    "\n",
    "- Run the model with an Early Stopping criterion that will restore the best weights of the Neural Net\n",
    "- Plot the loss and accuracy \n",
    "- Print the accuracy on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ü•° **Takeaways from the Early Stopping criterion:**\n",
    "\n",
    "- You can look at the üìö [**Early Stopping documentation**](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) to play with other parameters\n",
    "- You no longer need to have a look at the number of epochs as long as the model hits the stopping criterion. So, in the future, you should set a large number of epochs and the Early Stopping criterion will take care of stopping the training procedure before the model overfits! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Batch Size & Epochs\n",
    "\n",
    "üïµÔ∏è‚Äç‚ôÄÔ∏è Let's investigate the impact of the batch size on training a Neural Network and how we can use it to control how fast the parameters are updated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing with the Batch Size\n",
    "\n",
    "Let's run the previous model with **different batch sizes** (with the Early Stopping criterion included) and plot the results.\n",
    "\n",
    "üëâ Run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# RUN THIS CELL\n",
    "es = EarlyStopping(patience=20, restore_best_weights=True)\n",
    "\n",
    "for batch_size in [1, 4, 32]:\n",
    "    \n",
    "    model = initialize_model()\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_scaled,\n",
    "        y_train,\n",
    "        validation_split = 0.3,\n",
    "        epochs = 500,\n",
    "        batch_size = batch_size, \n",
    "        verbose = 0, \n",
    "        callbacks = [es]\n",
    "    )\n",
    "\n",
    "    results = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    plot_loss_accuracy(history, title=f'------ BATCH SIZE {batch_size} ------\\n The accuracy on the test set is of {results[1]:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùìQuestion: Impact of the Batch Size on the Convergence of a Neural Network\n",
    "\n",
    "Look at the oscillations of the accuracy and the loss according to the batch size number. \n",
    "\n",
    "Is this coherent with what we saw when playing with the TensorFlow Playground? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ‚ùìQuestion: Number of Parameter Updates\n",
    "\n",
    "How many weight optimizations are done within one epoch (considering the number of observations and the batch size)? Does one epoch have more weight updates with a large or with a small batch size?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your answer here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanations\n",
    "\n",
    "Copy and paste this code into a new cell, run it, and observe.\n",
    "        \n",
    "```python\n",
    "print(f\"There are {X_train.shape[0]} rows in the training set\")\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 2\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split = 0.3,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size,\n",
    "    verbose = 1\n",
    ")\n",
    "```        \n",
    "\n",
    "\n",
    "<u><b>Number of parameter updates:</b></u>\n",
    "\n",
    "- There are 1400 rows in the training set:\n",
    "    - $ 70 \\% \\times 1400 = 980 $ rows are used as the training set within the training set\n",
    "    - $ 30 \\% \\times 1400 = 420 $ rows are used as the validation set  \n",
    "- For each epoch, we run a forward/backward propagation $ \\large \\lceil \\frac{980}{batch size} \\rceil = \\lceil \\frac{980}{16}\\rceil = 62$ times\n",
    "- Without the Early Stopping Criterion, we will have _number of_ $ epochs \\times 62 = 2 \\times 62 = 124 $ iterations overall\n",
    "        \n",
    "<u><b>Impact of the batch size:</b></u>\n",
    "\n",
    "The smaller the batch size \n",
    "\n",
    "$ \\implies $ The more sub-iterations will be done  \n",
    "$ \\implies $ Parameters will be updated more frequently  \n",
    "$ \\implies $ We may need fewer epochs  \n",
    "\n",
    "_(but we also don't care too much about the number of epochs if we use an Early Stopping Criterion with a patience term anyway)_    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 2\n",
    "\n",
    "model = initialize_model()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    validation_split = 0.3,\n",
    "    epochs = epochs,\n",
    "    batch_size = batch_size, \n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.3) Regularization\n",
    "\n",
    "‚ùóÔ∏è**Neural Networks with complex architectures can quickly lead to overfitting** (_too many layers and/or neurons_)‚ùóÔ∏è\n",
    "\n",
    "üî• But since Dense Neural Networks are just activated linear regressions, the weights can be constrained using L1, L2, or L1-L2 penalties!\n",
    "\n",
    "üöì So, let's apply some L2 or L1 penalties to these neurons; as in Machine Learning, these penalties are called **`Regularizers`**.\n",
    "\n",
    "üìö <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/regularizers\">See `tf.keras.regularizers`</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observing Overfitting Before Regularizing\n",
    "\n",
    "First, let's initialize a model that has too many parameters for the task such that it overfits the training data quickly. To that purpose, let's not use any Early Stopping criterion.\n",
    "\n",
    "üéÅ Let's not waste time re-coding something that you are now used to, just run the following cell and observe what is happening üëá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 81596,
     "status": "ok",
     "timestamp": 1612905145614,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -60
    },
    "id": "XaOTe0-Yksyn"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL\n",
    "\n",
    "# 1. Model Architecture\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(25, activation='relu', input_dim=10))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(8, activation='softmax'))\n",
    "\n",
    "# 2. Model Compilation\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 3. Training \n",
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_split = 0.3,\n",
    "    epochs = 300,           # Notice that we are not using any Early Stopping Criterion\n",
    "    batch_size = 16, \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# 4. Evaluation\n",
    "results_train = model.evaluate(X_train_scaled, y_train, verbose = 0)\n",
    "results_test = model.evaluate(X_test_scaled, y_test, verbose = 0)\n",
    "\n",
    "\n",
    "# 5. Looking back at what happened during the training phase\n",
    "print(f'The accuracy on the testing set is {results_test[1]:.2f}...')\n",
    "print(f'...whereas the accuracy on the training set is {results_train[1]:.2f}!')\n",
    "plot_loss_accuracy(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è In our \"over-parameterized network\", some neurons became **too specific for the given training data**, preventing the network from generalizing to new data.\n",
    "\n",
    "üòï This led to some overfitting! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studying the Impact of Regularization on the Neural Network\n",
    "\n",
    "Change the previous code to integrate an L2 or L1 regularizer into your Dense Layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.4) Dropout Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction to Dropout Layers\n",
    "\n",
    "The role of a Dropout Layer is to randomly cancel the output of some neurons during the training phase, it prevents the network from getting too specific for the input data.\n",
    "\n",
    "Dropout Layers\n",
    "- ensure that no neuron can overspecialize in learning a pattern of the dataset because its output is sometimes canceled\n",
    "- force the information of an input to be spread across multiple neurons instead of only one specific neuron\n",
    "- are super straightforward to code üëå\n",
    "  - but what is going on _under the hood_? üë©üèª‚Äçüè´"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional Reading\n",
    "\n",
    "<details>\n",
    "    <summary>Click here for further explanations about Dropout Layers</summary>\n",
    "\n",
    "ü§î Remember what we said about neurons becoming **too specific**? \n",
    "\n",
    "**`BEGIN_EXPLANATIONS_ABOUT_DROPOUT_LAYERS`**\n",
    "\n",
    "---\n",
    "\n",
    "‚öΩÔ∏è  **A Football Analogy:**\n",
    "\n",
    "Think about a football team. There are 11 players on the pitch, but there are also players on the bench. Why? \n",
    "- The coach may want to substitute injured or tired players during the game\n",
    "- The team may be\n",
    "    - losing the game and willing to substitute a midfielder with a more **versatile player** who can be more offensive (= **mix of** midfielder/attacker roles) \n",
    "    - winning the game and would like to secure the result by replacing a midfielder with a more **versatile player** who can be more defensive (= **mix of** midfielder/defense roles)\n",
    "\n",
    "üí° Well, in a Neural Net, there is also a risk that a neuron over-specializes in detecting one pattern, where it would be advisable to keep it more versatile.\n",
    "\n",
    "---\n",
    "\n",
    "üìö **The goal of [Dropout Layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout) is to prevent neurons from over-specializing.**\n",
    "\n",
    "üßëüèª‚Äçüè´ How do Dropout Layers work?\n",
    "\n",
    "üëâ When we apply a **Dropout rate** of 20% to a layer $k$, 20% of the **selected neurons** will have their weights **temporarily set to 0** , which has the following consequences:\n",
    "1. A neuron computed at layer $k + 1$ considers all the weights as usual, but since some of them were temporarily set to 0, they were ‚Äúignored‚Äù while creating the neurons of this layer $k + 1$\n",
    "2. Once a batch of data points has been seen by the Neural Network (**forward propagation**) and 80% of the weights in a layer have been optimized/updated (**backward propagation** with the **Adam** optimizer), the Neural Network moves on to the forward propagation of the next batch, where it will use:\n",
    "   - 80% of the weights; the ones that were updated\n",
    "   - 20% of the weights; the ones that were previously ignored and had their values **temporarily** set to 0\n",
    "\n",
    "Based on these weights, we will go through this Dropout Layer again, which is going to temporarily ignore another 20% of the weights of a given layer. Be careful, the selection of this 20% is random, so the weights that will be ignored this time won't necessarily be the same as before!\n",
    "\n",
    "üëâ Think about the **Dropout rate** as a **sampling with replacement**\n",
    "\n",
    "üëâ By **randomly shutting down** different neurons at different epochs, we force the data points to be **analyzed by different neurons**. At the end of the day, these neurons will become **more versatile** instead of over-specializing!\n",
    "   \n",
    "---\n",
    "\n",
    "**`END_EXPLANATIONS_ABOUT_DROPOUT_LAYERS`**\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Studying the Impact of Dropout Layers on the Neural Network\n",
    "\n",
    "Include some Dropout layers in the architecture of your original model _(don't add regularizers here)_.\n",
    "\n",
    "What can you observe regarding the convergence of your model? What about its ability to generalize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Conclusions\n",
    "\n",
    "- ‚ùóÔ∏è If you train a Neural Network too much (too many layers, too many neurons, and/or too many epochs), it will overfit very quickly\n",
    "- ü•ä To prevent overfitting in Deep Learning, you can use Early Stopping, Regularization, and Dropout Layers\n",
    "- ‚ùóÔ∏è Be careful, if you use these techniques, you might end up on the other spectrum of the performance where your model would underfit the dataset!\n",
    "- üÜó You could potentially look at the batch size but we usually use 16 or 32; and as the French Computer Scientist [**Yann Lecun**](https://en.wikipedia.org/wiki/Yann_LeCun) said (Facebook x NYU):\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/data-science-images/DL/deep_learning_yann_lecun_batch_size.png\" alt=\"batch_size_yann_lecun\" width=\"500\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÅ Congratulations!\n",
    "\n",
    "üíæ Do not forget to `git add/commit/push` your notebook...\n",
    "\n",
    "üöÄ ... and move to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
